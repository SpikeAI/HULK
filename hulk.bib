%!TEX root = hulk.tex
%!TeX TS-program = pdflatex
%!TeX encoding = UTF-8 Unicode
%!TeX spellcheck = en-US
%!BIB TS-program = bibtex
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8

@ARTICLE{Kingma13,
   author = {{Kingma}, D.~P and {Welling}, M.},
    title = "{Auto-Encoding Variational Bayes}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.6114},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2013,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.6114K},
}


@article{Doersch2016,
	Abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
	Author = {Doersch, Carl},
	Journal = {arXiv:1606.05908 [cs, stat]},
	Keywords = {Computer Science - Learning, Statistics - Machine Learning},
	Month = jun,
	Title = {Tutorial on Variational Autoencoders},
	Url = {http://arxiv.org/abs/1606.05908},
	Year = {2016},}

@article{Eichhorn09,
  title={Natural image coding in V1: how much use is orientation selectivity?},
  author={Eichhorn, Jan and Sinz, Fabian and Bethge, Matthias},
  journal={PLoS computational biology},
  volume={5},
  number={4},
  pages={e1000336},
  year={2009},
  publisher={Public Library of Science}
}

@incollection{Zoran12,
	Author = {Zoran, Daniel and Weiss, Yair},
	Booktitle = {Advances in Neural Information Processing Systems 25},
	Editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	Pages = {1736--1744},
	Publisher = {Curran Associates, Inc.},
	Title = {Natural Images, Gaussian Mixtures and Dead Leaves},
	Url = {http://papers.nips.cc/paper/4758-natural-images-gaussian-mixtures-and-dead-leaves.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/4758-natural-images-gaussian-mixtures-and-dead-leaves.pdf}}

@article{Hansel12,
  title={The mechanism of orientation selectivity in primary visual cortex without a functional map},
  author={Hansel, David and van Vreeswijk, Carl},
  journal={Journal of Neuroscience},
  volume={32},
  number={12},
  pages={4049--4064},
  year={2012},
  publisher={Soc Neuroscience}
}

@article{Ringach02,
  title={Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex},
  author={Ringach, Dario L},
  journal={Journal of neurophysiology},
  volume={88},
  number={1},
  pages={455--463},
  year={2002},
  publisher={Am Physiological Soc}
}

@article{Mairal14,
  title={Sparse modeling for image and vision processing},
  author={Mairal, Julien and Bach, Francis and Ponce, Jean and others},
  journal={Foundations and Trends in Computer Graphics and Vision},
  volume={8},
  number={2-3},
  pages={85--283},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{Schwartz01,
	Author = {Schwartz, Odelia and Simoncelli, Eero P.},
	Citeulike-Article-Id = {9502425},
	Journal = {Nature Neuroscience},
	Number = {8},
	Pages = {819--25},
	Posted-At = {2011-07-04 11:21:48},
	Priority = {0},
	Title = {Natural signal statistics and sensory gain control},
	Volume = {4},
	Year = {2001}}

@article{Simoncelli17,
  title={Optimal Representations and Efficient Coding},
  author={Simoncelli, Eero P},
  journal={Annual Review of Vision Science},
  volume={3},
  number={1},
  year={2017},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, California 94303-0139, USA}
}

@article{Carandini12,
	Abstract = {There is increasing evidence that the brain relies on a set of canonical neural computations, repeating them across brain regions and modalities to apply similar operations to different problems. A promising candidate for such a computation is normalization, in which the responses of neurons are divided by a common factor that typically includes the summed activity of a pool of neurons. Normalization was developed to explain responses in the primary visual cortex and is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions. Normalization may underlie operations such as the representation of odours, the modulatory effects of visual attention, the encoding of value and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that it serves as a canonical neural computation.},
	Author = {Carandini, Matteo and Heeger, David J Dj},
	Doi = {10.1038/nrn3136},
	Journal = {Nature Reviews Neuroscience},
	Keywords = {Adaptation,Afferent Pathways,Anim,Physiological,contrast_response,divisive_normalization,normalization},
	Month = {jan},
	Number = {November},
	Pages = {1--12},
	Pmid = {22108672},
	Publisher = {Nature Publishing Group},
	Title = {Normalization as a canonical neural computation},
	Url = {http://discovery.ucl.ac.uk/1332718/ http://www.ncbi.nlm.nih.gov/pubmed/22108672 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3273486},
	Volume = {13},
	Year = {2012},
	}
@article{Loxley17,
abstract = {The two-dimensional Gabor function is adapted to natural image statistics, leading to a tractable probabilistic generative model that can be used to model simple cell receptive field profiles, or generate basis functions for sparse coding applications. Learning is found to be most pronounced in three Gabor function parameters representing the size and spatial frequency of the two-dimensional Gabor function and characterized by a nonuniform probability distribution with heavy tails. All three parameters are found to be strongly correlated, resulting in a basis of multiscale Gabor functions with similar aspect ratios and size-dependent spatial frequencies. A key finding is that the distribution of receptive-field sizes is scale invariant over a wide range of values, so there is no characteristic receptive field size selected by natural image statistics. The Gabor function aspect ratio is found to be approximately conserved by the learning rules and is therefore not well determined by natural image statistics. This allows for three distinct solutions: a basis of Gabor functions with sharp orientation resolution at the expense of spatial-frequency resolution, a basis of Gabor functions with sharp spatial-frequency resolution at the expense of orientation resolution, or a basis with unit aspect ratio. Arbitrary mixtures of all three cases are also possible. Two parameters controlling the shape of the marginal distributions in a probabilistic generative model fully account for all three solutions. The best-performing probabilistic generative model for sparse coding applications is found to be a gaussian copula with Pareto marginal probability density functions.},
author = {Loxley, P. N.},
doi = {10.1162/neco_a_00997},
issn = {0899-7667},
journal = {Neural Computation},
month = {oct},
number = {10},
pages = {2769--2799},
pmid = {28777727},
title = {The Two-Dimensional Gabor Function Adapted to Natural Image Statistics: A Model of Simple-Cell Receptive Fields and Sparse Structure in Images},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28777727 http://www.mitpressjournals.org/doi/abs/10.1162/neco_a_00997},
volume = {29},
year = {2017}
}
@article{Brito16,
  title={Nonlinear Hebbian learning as a unifying principle in receptive field formation},
  author={Brito, Carlos SN and Gerstner, Wulfram},
  journal={PLoS computational biology},
  volume={12},
  number={9},
  pages={e1005070},
  year={2016},
  publisher={Public Library of Science}
}
@article{Sandin17,
  author={Sandin, Fredrik and Martin-del-Campo, Sergio},
  journal={arXiv preprint arXiv:1611.09333},
booktitle = {2017 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2017.7965902},
isbn = {978-1-5090-6182-2},
month = {may},
pages = {557--564},
publisher = {IEEE},
title = {Dictionary learning with equiprobable matching pursuit},
url = {http://ieeexplore.ieee.org/document/7965902/},
year = {2017}
}

@article{Barlow61,
  title={The coding of sensory messages},
  author={Barlow, Horace B},
  journal={Current problems in animal behavior},
  year={1961},
  publisher={Cambridge University Press}
}

@inproceedings{Vincent08,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008},
  organization={ACM}
}

@article{MakhzaniF13,
  author    = {Alireza Makhzani and
               Brendan J. Frey},
  title     = {k-Sparse Autoencoders},
  journal   = {CoRR},
  volume    = {abs/1312.5663},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5663},
  archivePrefix = {arXiv},
  eprint    = {1312.5663},
  timestamp = {Wed, 07 Jun 2017 14:42:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MakhzaniF13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Papyan16,
  title={Convolutional neural networks analyzed via convolutional sparse coding},
  author={Papyan, Vardan and Romano, Yaniv and Elad, Michael},
  journal={stat},
  volume={1050},
  pages={27},
  year={2016}
}


@article{Aurelio2006,
	Author = {Aurelio, Marc and Christopher, Ranzato and Sumit, Poultney and Yann, Chopra},
	Journal = {New York},
	Title = {Efficient Learning of Sparse Representations with an Energy-Based Model},
	Year = {2006}}

@inproceedings{poultney2007efficient,
  title={Efficient learning of sparse representations with an energy-based model},
  author={Poultney, Christopher and Chopra, Sumit and Cun, Yann L and others},
  booktitle={Advances in neural information processing systems},
  pages={1137--1144},
  year={2007}
}

@inproceedings{Ranzato10,
title={Modeling pixel means and covariances using factorized third-order Boltzmann machines},
author={Marc’Aurelio Ranzato and Hinton, Geoffrey E},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
pages={2551--2558},
year={2010},
organization={IEEE}
}
